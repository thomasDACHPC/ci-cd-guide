# Local Kubernetes Setup
## Prerequisites and System used for this Guide
- macOS Somna Version 14.5
- Docker with DockerID
  `brew install --cask docker`
- Minikube
  `brew install minikube`
- kubectl
  `brew install kubectl`
- Java 17 or later
- Maven
- Flux
  `brew install fluxcd/tap/flux`

## Java Spring Web Application

### Fork the [CI/CD-Guide Project](https://github.com/thomasDACHPC/ci-cd-guide/tree/main)
The example project contains a simple Java Spring Web Application in
`src/main/java/com/example/spring_boot_docker/SpringBootDockerApplication.java`:
```
package com.example.spring_boot_docker;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@SpringBootApplication
@RestController
public class SpringBootDockerApplication {

	@RequestMapping("/")
	public String home() {
		return "Hello from the Kubernetes Cluster!";
	}

	public static void main(String[] args) {
		SpringApplication.run(SpringBootDockerApplication.class, args);
	}
}
```
When started, accessing [`http://localhost:8080/`]() will display the message returned by the *RequestMapping("/")-Method*. 
Stop the application before continuing.

### Package the Java Application
Use `./mvnw package` withing the project to package the application as .jar file.

## Containerization of the Application with Docker

### Write a Dockerfile to create an Docker Image of the Application
After packaging the application the next step is to containerize it and create an image.
In this guide a Dockerfile is used for this process.
Create a file called `Dockerfile` with the following content:
```
FROM amazoncorretto:21.0.4-alpine3.18
ARG JAR_FILE=target/*.jar
COPY ${JAR_FILE} app.jar
ENTRYPOINT ["java","-jar","/app.jar"]
```
This Dockerfile is used to set up a Java environment and copy our application into this environment. The entry point ensures that the application is executed directly when the container is started.

### Build the Docker Image
`docker build . -t spring-boot-app`\
The `-t` option tags the image as ***spring-boot-app***.
Note that the docker deamon has to run to execute the command (i.e. start Docker Desktop for example)

### Run a Docker Container (Optional)
You can test if the imaging process was successful by running the command\
`docker run -p 8080:8080 <image-id>`\
Again, accessing [`http://localhost:8080/`]() will display the message returned by the *RequestMapping("/")-Method*.
Please shut down the container before continuing.

### Push the Image to the Docker Container Registry (DockerID required)
Use the following command to push the image to the Docker Container Registry (Docker Hub). To be compliant with this guide use `cicdguideproject:v1.0.0` as `<docker-repository-name>:<tag>`.
`<docker-id>` is your docker username in lowercase.
```
docker tag <current-image-name> <docker-id>/<docker-repository-name>:<tag>
docker push <docker-id>/<docker-repository-name>:<tag>
```
The first command changes the name of the image and adds an optional tag (for example for versioning). The second command actually pushes the image to the container registry.

### Setup Minikube on MacOs
Minikube is an open-source tool that allows you to run a single-node Kubernetes cluster on your local machine.
Minikube uses a hypervisor to create a virtual machine or a container runtime to simulate a Kubernetes environment.
Due to the limitations of the Docker driver on Apple Silicon Chips we will use a QEMU driver for virtualization.
The following commands will install QEMU and *socket_vmnet* which will allow Minikube to run `minikube tunnel` command if needed ([source](https://medium.com/@sushantkumarsinha22/kubernetes-setting-up-ingress-on-apple-silicon-mac-m1-5fb6bddcb838)).
```
brew install qemu
brew install socket_vmnet
brew tap homebrew/services
HOMEBREW=$(which brew) && sudo ${HOMEBREW} services start socket_vmnet
```
The minikube cluster ist started with\
`minikube start --driver qemu --network socket_vmnet`.

### Prepare Minikube for Kubernetes Ingress
Later in this guide we will establish a Kubernetes Ingress. A corresponding addon has to be enabled in Minikube\
`minikube addons enable ingress`

## Kubernetes
Now we are accessing the the universe of Kubernetes. Kubernetes, often abbreviated as K8s, is an open-source container orchestration platform designed to automate the deployment, scaling, and management of containerized applications. 
### Core Components of Kubernetes (generated by ChatGPT)
- **Cluster**: The set of nodes (machines) that run containerized applications managed by Kubernetes.
- **Node**: A single machine in the Kubernetes cluster. It runs containerized applications and is managed by the control plane.
- **Pod**: The smallest deployable unit in Kubernetes, which can contain one or more containers. Pods are designed to run a single instance of a given application.
- **Deployment**: A Kubernetes resource that manages a set of identical pods, ensuring the correct number of pods are running and updating them as needed.
- **Service**: An abstraction that defines a logical set of pods and a policy by which to access them, usually via an IP address or DNS name.
- **Namespace**: A way to divide cluster resources between multiple users. Namespaces are a way to organize objects in the cluster and are often used for multi-tenant environments.

### Create a Kubernetes Deployment File (deployment.yaml)
To tell Kubernetes which application and how many pods should be deployed a deployment configuration is necessary. A simple `deployment.yaml` file can be found in the project folder `deployment`.
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app-deployment
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: spring-boot-app
  template:
    metadata:
      labels:
        app: spring-boot-app
    spec:
      containers:
        - name: spring-boot-app
          image: thomasdachpc/cicdguideproject:v1.0.0
          ports:
            - containerPort: 8080
```
A few comments on this file:


```
kind: Deployment
metadata:
	name: spring-boot-app-deployment
	namespace: default
```

Metadata sets a unique name for the deployment and its namespace. For this guide, do not change the namespace.
```
replicas: 2
```
_Replicas_ defines how many pods of the application should be created by Kubernetes.

```
containers:
	- name: spring-boot-app
    	image: thomasdachpc/cicdguideproject:v1.0.0
        ports:
        	- containerPort: 8080
```
These lines of code set the application image which should be deployed by Kubernetes. The *image* is equivalent to `<docker-repository-name>:<tag>` in this case. 
The *containerPort* defines the port on which the application is accessible within the Kubernetes cluster.

For more information about deployments refer to the [Kubernetes documentation](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)!

### Create a Kubernetes Service File (service.yaml)
The next part is about the configuration of a service. Again, a simple `service.yaml` file can be found in the project folder `deployment`.
In Kubernetes, a Service is a method for exposing a network application that is running as one or more Pods in your cluster.
The first type of service we will use is the _load balancer_. It allows to access an application from the outside of the cluster.
```
apiVersion: v1
kind: Service
metadata:
  name: spring-boot-app-service
  namespace: default
spec:
  type: LoadBalancer
  selector:
    app: spring-boot-app
  ports:
    - protocol: TCP
      port: 81
      targetPort: 8080
```
A few comments on this file:

```
kind: Service
metadata:
	name: spring-boot-app-deployment
	namespace: default
```
Metadata sets a unique name and the namespace for the service. For this guide, do not change the namespace.

```
spec:
  type: LoadBalancer
  selector:
    app: spring-boot-app
  ports:
  - protocol: TCP
    port: 81
    targetPort: 8080
```
In these lines of code the type of the service is specified as well as the application.
All traffic arriving at port 81 of the service is forwarded to port 8080 of the application _spring-boot-app_.
The name has to match the corresponding naming in the deployment file.

### Apply the configuration files
Both files can be applied to the Kubernetes cluster by executing the following commands:
```
kubectl apply -f deployment/deployment.yaml
kubectl apply -f deployment/service.yaml
```

### Check status
After applying the configuration files check the cluster status with the following command:
```
kubectl get all
```
You should see two pods as well as a service of type LoadBalancer.
Looking at the LoadBalancer service the External-IP is _\<none\>_.
To access the service and the corresponding application from outside the cluster we have to create a routable IP.
### Create a Routable IP
In another terminal window issue the following command:
``` 
minikube tunnel
```
The terminal has to stay open.\
Check the status of the cluster again.
The LoadBalancer service should now have an External-IP.
Accessing `<IP>:81` with your browser should display the known message from the RequestMapping-Method.
At this point, you have deployed an application in Kubernetes and can access it from outside the cluster!

### Creating an Ingress (ingress.yaml, ingress-service.yaml)
An [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. 
Traffic routing is controlled by rules defined on the Ingress resource.
An Ingress may be configured to give Services externally-reachable URLs, load balance traffic, terminate SSL / TLS, 
and offer name-based virtual hosting. 
An Ingress controller is responsible for fulfilling the Ingress, usually with a load balancer, 
though it may also configure your edge router or additional frontends to help handle the traffic.

An example `ingress.yaml` configuration file as well as an `ingress-service.yaml` can be found in the `deployment` folder.
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - host: my-spring-boot-app.com
      http:
        paths:
          - path: /example
            pathType: Prefix
            backend:
              service:
                name: my-spring-boot-app-cluster-service
                port:
                  number: 81
```
Let us break down the Ingress configuration starting with the _spec_ section.
```
    - host: my-spring-boot-app.com
      http:
        paths:
          - path: /example
            pathType: Prefix
```
This part defines a base URL _my-spring-boot-app.com_  where the Ingress is accessible and an additional subpath _/example_.
The _pathType: Prefix_ indicates that every URL starting with _my-spring-boot-app.com/example_ is allowed to use to reach the Ingress (e.g. _my-spring-boot-app.com/example/anotherpath_).

```
              service:
                name: my-spring-boot-app-cluster-service
                port:
                  number: 81
```
The service-part defines the service and its port the Ingress is forwarding traffic to. In this case it is a ClusterIP service configured in the ingress-service file.
The configuration is similar to the previous LoadBalancer. A ClusterIP service enables the communication with an application only within the cluster.
Let us get to the _metadata_ section.
```
metadata:
  name: example-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
```

Metadata contains the name and the namespace of the Ingress. 
Remember that base URL _my-spring-boot-app.com_ is defined a base URL for the Ingress. The annotation _nginx.ingress.kubernetes.io/rewrite-target: /_ ensures that every
URL will be rewritten as simple base URL before forwarding it to the application. This is important if the application does not support a subpath.
An example:
Our Spring applications method is annotated with _@RequestMapping("/")_ so it just listens to the base URL.
Our Ingress defines _my-spring-boot-app.com_ as base URL and _/example_ as a subpath.
Without rewriting to the base URL, accessing the Ingress via _my-spring-boot-app.com/example_ would lead to forwarding of _my-spring-boot-app.com/example_
to the application. Because the application just listens to _my-spring-boot-app.com_ we would get a _404 Not found_ error. With the rewrite annotation
_my-spring-boot-app.com/example_ will be rewritten and forwarded as _my-spring-boot-app.com/_ to the application.

---
Overall, our current cluster architecture looks like this:
\
\
![cluster-structure.png](images/cluster-structure.png)

Apply both files with
```
kubectl apply -f deployment/ingress.yaml
kubectl apply -f deployment/ingress-service.yaml
```
In addition to accessing the application via the External-IP of the LoadBalancer service you can now use the URL _my-spring-boot-app.com/example_.
As _my-spring-boot-app.com_ is just a self defined URL your computer does not know how to resolve it to an IP address.
To solve this problem we need the Minkube IP address. We can get the address with `minikube IP`.
Note, that the Ingress is not accessible via the IP address only.
There are two options to use the URL to access the application:
1. Use a curl command and add the _--resolve_ option\
curl http://my-spring-boot-app.com/v2 --resolve "my-spring-boot-app.com:81:\<minikube IP\>"
2. Access your hosts file with `sudo nano /etc/hosts ` and add the following line of code. Saving the file enables to reach the domain URL my-spring-boot-app.com using your browser.\
`<minikube IP>   my-spring-boot-app.com`

### Create a NodePort Service (nodeport-service.yaml)

Another service we can use to expose our cluster application to the outside is the NodePort service. NodePort uses the Minikube IP address and a
user defined port to make the application accessible. An example NodePort definition can be found in the `nodeport-service.yaml`in the `deployment` folder.

```
apiVersion: v1
kind: Service
metadata:
  name: my-spring-boot-app-nodeport-service
  namespace: default
spec:
  type: NodePort
  selector:
    app: spring-boot-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
      nodePort: 30005
```

Again, let us break down the configuration.
```
metadata:
  name: my-spring-boot-app-nodeport-service
  namespace: default
```

As for the other services _metadata_ defines a unique name a namespace for the service.

```
spec:
  type: NodePort
  selector:
    app: spring-boot-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
      nodePort: 30005
```

The spec section sets the type of service (NodePort) and the name of the application the service forwards to.
_port_ refers to the port the service is accessible within the cluster.\
_targetPort_ defines the application port to which the traffic is forwarded to.\
_nodePort_ is the port where the NodePort service is accessible from the outside.

Applying this service file with `kubectl apply -f deployment/nodeport-service.yaml` allows to access the application
from your browser with `<Minikube IP>:<nodePort>`.

---

For this guide, each service has its own file. For a more compact configuration of your cluster, you can create a single 
yaml file containing all services separated by `---` (yaml syntax for an in-file file separation).

## FluxCD

FluxCD, often referred to simply as Flux, is a open-source toolset for continuous deployment (CD) on Kubernetes.
It automates the process of deploying and managing applications in a Kubernetes cluster by continuously synchronizing the cluster state with, for example, 
a Git repository. This practice is known as "GitOps."\
The `flux bootstrap` command deploys the Flux controllers on Kubernetes cluster(s) and configures the controllers to sync the cluster(s) state from a Git repository. 
Besides installing the controllers, the bootstrap command pushes the Flux manifests to the Git repository and configures Flux to update itself from Git,
After running the bootstrap command, any operation on the cluster(s) (including Flux upgrades) can be done via Git push, without the need to connect to the Kubernetes API.
A good visualization of this process can be found in the official Flux installation guide in the section [Bootstrap with Flux CLI](https://fluxcd.io/flux/installation/#bootstrap-with-flux-cli).\
The Flux documentation contains [bootstrap instructions](https://fluxcd.io/flux/installation/bootstrap/) for various repositories. 
In this guide, GitHub is used as the repository. Please follow the official documentation for [bootstrapping Flux for GitHub](https://fluxcd.io/flux/installation/bootstrap/github/).\
The naming conventions of this guide follow the GitHub bootstrap command suggested by the documentation:
```
flux bootstrap github \
  --owner=github-username\
  --repository=kubernetes-deployment \
  --branch=main \
  --path=./clusters/my-cluster \
  --personal
```

The bootstrap command creates a new private GitHub repository named _kubernetes-deployment_ with the following folder and file structure:
`path=./clusters/my-cluster` is the path where Flux starts to look for configuration files to synchronize with your Kubernetes cluster.

```
clusters
  - my-cluster
      - flux-system
          - gotk-components.yaml
          - gotk-sync.yaml
          - kustomization.yaml
```

`gotk-components.yaml` and `gotk-sync.yaml` are the configuration files for Flux itself. We will let them unchanged for now.
The `kustomization.yaml`is a file to define resources Flux uses to synchronize with the Kubernetes cluster:

```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- gotk-components.yaml
- gotk-sync.yaml
```

Resources not explicitly listed in a kustomization.yaml will be ignored by Flux.\
For the rest of this guide you can decide if you want to operate on the kubernetes-deployment repository locally or via the GitHub UI.

Create a few new folders and copy the files from the `deployment` directory from the ci-cd-guide repository to the new kubernetes-deployment repository
according to the following folder and file structure:

```
clusters
  - my-cluster
      - deployment
          - deployment.yaml
      - ingress
          - ingress.yaml
          - ingress-service.yaml
      - service
          - nodeport-service.yaml
          - service.yaml
      - flux-system
          - gotk-components.yaml
          - gotk-sync.yaml
          - kustomization.yaml
```

As said, Flux will ignore resources not specified in a kustomization.yaml.
Therefore, we create some new __kustomization.yaml__ files:

---

<pre>
clusters
  - my-cluster
      - deployment
          - deployment.yaml
      - <b>kustomization.yaml</b>
</pre>
with the following kustomization.yaml:
```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- deployment.yaml
```

---

<pre>
clusters
  - my-cluster
      - ingress
          - ingress.yaml
          - ingress-service.yaml
      - <b>kustomization.yaml</b>
</pre>
with the following kustomization.yaml:
```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- ingress.yaml
- ingress-service.yaml
```

---

<pre>
clusters
  - my-cluster
      - ingress
          - service.yaml
          - nodeport-service.yaml
      - <b>kustomization.yaml</b>
</pre>
with the following kustomization.yaml:
```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- service.yaml
- nodeport-service.yaml
```

---

<pre>
clusters
  - my-cluster
      - deployment
          - deployment.yaml
          - kustomization.yaml
      - ingress
          - ingress.yaml
          - ingress-service.yaml
          - kustomization.yaml
      - service
          - nodeport-service.yaml
          - service.yaml
          - kustomization.yaml
      - flux-system
          - gotk-components.yaml
          - gotk-sync.yaml
          - kustomization.yaml
      - <b>kustomization.yaml</b>
</pre>
with the following kustomization.yaml:
```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- ./deployment
- ./ingress
- ./service
- ./flux-system
```

---

Now, Flux will automatically synchronize changes to the configuration files with our Kubernetes cluster.
Let us try this out.
Issue the command `k get all`.
As defined in our `deployment.yaml` under `replicas`there should be two pod running.
In the `kubernetes-deployment` repository, change the number of replicas to four:

<pre>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app-deployment
  namespace: default
spec:
  <b>replicas: 4</b>
  selector:
    matchLabels:
      app: spring-boot-app
  template:
    metadata:
      labels:
        app: spring-boot-app
    spec:
      containers:
        - name: spring-boot-app
          image: thomasdachpc/cicdguideproject:v1.0.0
          ports:
            - containerPort: 8080
</pre>

Apply this change and wait about a minute. Flux will recognize the change in the deployment file and apply the new configuration to our Kubernetes cluster.
Execute `k get all` again. Now, there should be four pods running.\
A useful command to check the synchronization status of Flux is `flux get kustomizations -A`.

From now on we can configure the Kubernetes cluster by pushing or changing files in a GitHub repository instead of manually applying files.



## Jenkins (WIP)
Jenkins is an open-source automation server that is widely used for continuous integration (CI) and continuous delivery (CD) in software development. 
It helps automate parts of the software development process related to building, testing, and deploying applications, which leads to more efficient and reliable workflows.
To install Jenkins in your Kubernetes cluster follow sections [Kubernetes Jenkins Deployment](https://www.jenkins.io/doc/book/installing/kubernetes/#kubernetes-jenkins-deployment) 
and [Post-installation setup wizard](https://www.jenkins.io/doc/book/installing/kubernetes/#kubernetes-jenkins-deployment) of the official Jenkins handbook.